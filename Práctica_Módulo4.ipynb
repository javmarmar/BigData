{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "from nltk.chunk import *\n",
    "from nltk.chunk.util import *\n",
    "from nltk.chunk.regexp import *\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cargamos el corpus de prueba: \n",
      "\n",
      "Ponme un pincho de tortilla, quiero una pizza margherita, Quiero una hamburguesa,Podría ser un bocadillo de calamares, Una ración de patatas, Quería pedir dos cheeseburger,una ración de jamón ibérico, Dos pizzas medianas barbacoa, Un kebab mixto,Chili con queso,por favor\n"
     ]
    }
   ],
   "source": [
    "#***************************************************************************************\n",
    "# 1. Cargamos el corpus de textos\n",
    "#***************************************************************************************\n",
    "\n",
    "print(\"\\n\\n1. Cargamos el corpus de prueba: \\n\")\n",
    "\n",
    "corpus = \"Ponme un pincho de tortilla, quiero una pizza margherita, Quiero una hamburguesa,Podría ser un bocadillo de calamares, Una ración de patatas, Quería pedir dos cheeseburger,una ración de jamón ibérico, Dos pizzas medianas barbacoa, Un kebab mixto,Chili con queso,por favor\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto con unigramas: 87.65970871234029\n",
      "Acierto con bigramas: 89.42636311057363\n",
      "Acierto con trigramas: 89.40007361059993\n",
      "Acierto con HMMs: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "sents = cess_esp.tagged_sents()\n",
    "\n",
    "#Metemos en el conjunto de entrenamiento el 90% de las frases, y el restante 10% en el conjunto de test\n",
    "\n",
    "training = []\n",
    "test = []\n",
    "for i in range(len(sents)):\n",
    "    if i % 10:\n",
    "        training.append(sents[i])\n",
    "    else:\n",
    "        test.append(sents[i])\n",
    "\n",
    "#Entrenamos los 4 posibles taggers con el corpus CESS_ESP\n",
    "\n",
    "unigram_tagger = UnigramTagger(training)\n",
    "bigram_tagger = BigramTagger(training, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(training, backoff=bigram_tagger)\n",
    "hmm_tagger = HiddenMarkovModelTagger.train(training)\n",
    "\n",
    "print ('Acierto con unigramas:', unigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con bigramas:', bigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con trigramas:', trigram_tagger.evaluate(test)*100)\n",
    "print ('Acierto con HMMs:', hmm_tagger.evaluate(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2. Frases: ['Ponme un pincho de tortilla, quiero una pizza margherita, Quiero una hamburguesa,Podría ser un bocadillo de calamares, Una ración de patatas, Quería pedir dos cheeseburger,una ración de jamón ibérico, Dos pizzas medianas barbacoa, Un kebab mixto,Chili con queso,por favor']\n"
     ]
    }
   ],
   "source": [
    "# Dividimos el corpus de prueba en frases\n",
    "\n",
    "sentences = nltk.tokenize.sent_tokenize(corpus)\n",
    "print (\"\\n\\n2. Frases:\",sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Tokens: ['Ponme', 'un', 'pincho', 'de', 'tortilla', ',', 'quiero', 'una', 'pizza', 'margherita', ',', 'Quiero', 'una', 'hamburguesa', ',', 'Podría', 'ser', 'un', 'bocadillo', 'de', 'calamares', ',', 'Una', 'ración', 'de', 'patatas', ',', 'Quería', 'pedir', 'dos', 'cheeseburger', ',', 'una', 'ración', 'de', 'jamón', 'ibérico', ',', 'Dos', 'pizzas', 'medianas', 'barbacoa', ',', 'Un', 'kebab', 'mixto', ',', 'Chili', 'con', 'queso', ',', 'por', 'favor']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizamos las frases\n",
    "\n",
    "tokens = nltk.word_tokenize(corpus)\n",
    "print (\"\\n\\n3. Tokens:\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGER UNIGRAMA: [('Ponme', None), ('un', 'di0ms0'), ('pincho', None), ('de', 'sps00'), ('tortilla', 'ncfs000'), (',', 'Fc'), ('quiero', 'vmip1s0'), ('una', 'di0fs0'), ('pizza', None), ('margherita', None), (',', 'Fc'), ('Quiero', 'vmip1s0'), ('una', 'di0fs0'), ('hamburguesa', None), (',', 'Fc'), ('Podría', None), ('ser', 'vsn0000'), ('un', 'di0ms0'), ('bocadillo', None), ('de', 'sps00'), ('calamares', None), (',', 'Fc'), ('Una', 'di0fs0'), ('ración', None), ('de', 'sps00'), ('patatas', 'ncfp000'), (',', 'Fc'), ('Quería', None), ('pedir', 'vmn0000'), ('dos', 'dn0cp0'), ('cheeseburger', None), (',', 'Fc'), ('una', 'di0fs0'), ('ración', None), ('de', 'sps00'), ('jamón', 'ncms000'), ('ibérico', None), (',', 'Fc'), ('Dos', 'dn0cp0'), ('pizzas', None), ('medianas', 'aq0fp0'), ('barbacoa', None), (',', 'Fc'), ('Un', 'di0ms0'), ('kebab', None), ('mixto', 'aq0ms0'), (',', 'Fc'), ('Chili', None), ('con', 'sps00'), ('queso', None), (',', 'Fc'), ('por', 'sps00'), ('favor', 'ncms000')]\n",
      "________________________\n",
      "TAGGER BIGRAMA: [('Ponme', None), ('un', 'di0ms0'), ('pincho', None), ('de', 'sps00'), ('tortilla', 'ncfs000'), (',', 'Fc'), ('quiero', 'vmip1s0'), ('una', 'di0fs0'), ('pizza', None), ('margherita', None), (',', 'Fc'), ('Quiero', 'vmip1s0'), ('una', 'di0fs0'), ('hamburguesa', None), (',', 'Fc'), ('Podría', None), ('ser', 'vsn0000'), ('un', 'di0ms0'), ('bocadillo', None), ('de', 'sps00'), ('calamares', None), (',', 'Fc'), ('Una', 'di0fs0'), ('ración', None), ('de', 'sps00'), ('patatas', 'ncfp000'), (',', 'Fc'), ('Quería', None), ('pedir', 'vmn0000'), ('dos', 'dn0cp0'), ('cheeseburger', None), (',', 'Fc'), ('una', 'di0fs0'), ('ración', None), ('de', 'sps00'), ('jamón', 'ncms000'), ('ibérico', None), (',', 'Fc'), ('Dos', 'dn0cp0'), ('pizzas', None), ('medianas', 'aq0fp0'), ('barbacoa', None), (',', 'Fc'), ('Un', 'di0ms0'), ('kebab', None), ('mixto', 'aq0ms0'), (',', 'Fc'), ('Chili', None), ('con', 'sps00'), ('queso', None), (',', 'Fc'), ('por', 'sps00'), ('favor', 'ncms000')]\n",
      "________________________\n",
      "TAGGER TRIGRAMA: [('Ponme', None), ('un', 'di0ms0'), ('pincho', None), ('de', 'sps00'), ('tortilla', 'ncfs000'), (',', 'Fc'), ('quiero', 'vmip1s0'), ('una', 'di0fs0'), ('pizza', None), ('margherita', None), (',', 'Fc'), ('Quiero', 'vmip1s0'), ('una', 'di0fs0'), ('hamburguesa', None), (',', 'Fc'), ('Podría', None), ('ser', 'vsn0000'), ('un', 'di0ms0'), ('bocadillo', None), ('de', 'sps00'), ('calamares', None), (',', 'Fc'), ('Una', 'di0fs0'), ('ración', None), ('de', 'sps00'), ('patatas', 'ncfp000'), (',', 'Fc'), ('Quería', None), ('pedir', 'vmn0000'), ('dos', 'dn0cp0'), ('cheeseburger', None), (',', 'Fc'), ('una', 'di0fs0'), ('ración', None), ('de', 'sps00'), ('jamón', 'ncms000'), ('ibérico', None), (',', 'Fc'), ('Dos', 'dn0cp0'), ('pizzas', None), ('medianas', 'aq0fp0'), ('barbacoa', None), (',', 'Fc'), ('Un', 'di0ms0'), ('kebab', None), ('mixto', 'aq0ms0'), (',', 'Fc'), ('Chili', None), ('con', 'sps00'), ('queso', None), (',', 'Fc'), ('por', 'sps00'), ('favor', 'ncms000')]\n",
      "________________________\n",
      "TAGGER HMMs: [('Ponme', 'sps00'), ('un', 'di0ms0'), ('pincho', 'ncms000'), ('de', 'sps00'), ('tortilla', 'ncfs000'), (',', 'Fc'), ('quiero', 'vmis3s0'), ('una', 'di0fs0'), ('pizza', 'ncfs000'), ('margherita', 'aq0fs0'), (',', 'Fc'), ('Quiero', 'vmis3s0'), ('una', 'di0fs0'), ('hamburguesa', 'ncfs000'), (',', 'Fc'), ('Podría', 'vmip3s0'), ('ser', 'vsn0000'), ('un', 'di0ms0'), ('bocadillo', 'ncms000'), ('de', 'sps00'), ('calamares', 'np0000l'), (',', 'Fc'), ('Una', 'di0fs0'), ('ración', 'ncfs000'), ('de', 'sps00'), ('patatas', 'ncfp000'), (',', 'Fc'), ('Quería', 'cc'), ('pedir', 'vmn0000'), ('dos', 'dn0cp0'), ('cheeseburger', 'ncmp000'), (',', 'Fc'), ('una', 'di0fs0'), ('ración', 'ncfs000'), ('de', 'sps00'), ('jamón', 'ncms000'), ('ibérico', 'aq0ms0'), (',', 'Fc'), ('Dos', 'dn0cp0'), ('pizzas', 'ncfp000'), ('medianas', 'aq0fp0'), ('barbacoa', 'ncfp000'), (',', 'Fc'), ('Un', 'di0ms0'), ('kebab', 'ncms000'), ('mixto', 'aq0ms0'), (',', 'Fc'), ('Chili', 'vmis3s0'), ('con', 'sps00'), ('queso', 'np0000l'), (',', 'Fc'), ('por', 'sps00'), ('favor', 'ncms000')]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los tags con los 4 métodos\n",
    "\n",
    "tagged1 = unigram_tagger.tag(tokens)\n",
    "print (\"TAGGER UNIGRAMA:\",tagged1)\n",
    "print (\"________________________\")\n",
    "tagged2 = bigram_tagger.tag(tokens)\n",
    "print (\"TAGGER BIGRAMA:\",tagged2)\n",
    "print (\"________________________\")\n",
    "tagged3 = trigram_tagger.tag(tokens)\n",
    "print (\"TAGGER TRIGRAMA:\",tagged3)\n",
    "print (\"________________________\")\n",
    "tagged4 = hmm_tagger.tag(tokens)\n",
    "print (\"TAGGER HMMs:\",tagged4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedido_cantidad(sentence):\n",
    "\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    grammar=r'''\n",
    "    Comida: \n",
    "    {<CD>*<NN><IN>*<NN>+} \n",
    "    {<CD>*<NN>+}  \n",
    "    {<JJ>*<NN>+}\n",
    "     \n",
    "    Cantidad: {<JJ>}\n",
    "    {<CD>}\n",
    "    {<DT>}\n",
    "    '''\n",
    "    resultado = RegexpParser(grammar).parse(tagged)\n",
    "    print(resultado)\n",
    "    data = []\n",
    "    for nodo in resultado:\n",
    "        if type(nodo) == tuple:\n",
    "          continue\n",
    "        tipo = nodo.label()\n",
    "        for elemento in nodo:\n",
    "          if type(elemento) != tuple:\n",
    "            continue\n",
    "          palabra, categoria = elemento\n",
    "          if tipo == 'Comida':\n",
    "            data.append(dict(Comida=palabra, Cantidad=1))\n",
    "               \n",
    "    return print(data)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenido a ***** ¿Cuál es su pedido?\n",
      "una pizza y bocata\n",
      "(S (Cantidad una/JJ) (Comida pizza/NN y/NN bocata/NN))\n",
      "[{'Comida': 'pizza', 'Cantidad': 1}, {'Comida': 'y', 'Cantidad': 1}, {'Comida': 'bocata', 'Cantidad': 1}]\n"
     ]
    }
   ],
   "source": [
    "print (\"Bienvenido a ***** ¿Cuál es su pedido?\")\n",
    "ped=input()\n",
    "pedido_cantidad(ped)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
